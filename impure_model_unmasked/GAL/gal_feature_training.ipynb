{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open('../unmasked_cropped.pkl','rb'))\n",
    "y = pickle.load(open('../labels.pkl','rb'))\n",
    "arc_lengths = pickle.load(open('./arcLengths.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_lengths = np.array(arc_lengths)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(932,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.04705882, 0.0745098 , 0.19215686],\n",
       "         [0.04705882, 0.04313725, 0.13333333],\n",
       "         [0.04313725, 0.03137255, 0.11764706],\n",
       "         ...,\n",
       "         [0.06666667, 0.12156863, 0.28235294],\n",
       "         [0.05098039, 0.11372549, 0.28235294],\n",
       "         [0.03137255, 0.10588235, 0.28235294]],\n",
       "\n",
       "        [[0.04313725, 0.06666667, 0.18039216],\n",
       "         [0.04313725, 0.03921569, 0.12941176],\n",
       "         [0.04705882, 0.04313725, 0.13333333],\n",
       "         ...,\n",
       "         [0.03529412, 0.08627451, 0.23137255],\n",
       "         [0.05098039, 0.11372549, 0.27843137],\n",
       "         [0.03921569, 0.11764706, 0.30196078]],\n",
       "\n",
       "        [[0.03921569, 0.05490196, 0.16470588],\n",
       "         [0.03921569, 0.04313725, 0.12941176],\n",
       "         [0.02352941, 0.03529412, 0.13333333],\n",
       "         ...,\n",
       "         [0.01568627, 0.04705882, 0.17647059],\n",
       "         [0.05098039, 0.11372549, 0.27058824],\n",
       "         [0.05098039, 0.12941176, 0.31372549]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12941176, 0.26666667, 0.58039216],\n",
       "         [0.0627451 , 0.19215686, 0.49019608],\n",
       "         [0.2745098 , 0.39215686, 0.63529412],\n",
       "         ...,\n",
       "         [0.01568627, 0.01568627, 0.03921569],\n",
       "         [0.01568627, 0.01568627, 0.03921569],\n",
       "         [0.01568627, 0.01568627, 0.03921569]],\n",
       "\n",
       "        [[0.17254902, 0.30196078, 0.6       ],\n",
       "         [0.02352941, 0.14509804, 0.41960784],\n",
       "         [0.2627451 , 0.36078431, 0.58431373],\n",
       "         ...,\n",
       "         [0.01568627, 0.01568627, 0.03921569],\n",
       "         [0.01568627, 0.01568627, 0.03921569],\n",
       "         [0.01568627, 0.01568627, 0.03921569]],\n",
       "\n",
       "        [[0.1254902 , 0.25490196, 0.5372549 ],\n",
       "         [0.01176471, 0.11372549, 0.36078431],\n",
       "         [0.05882353, 0.13333333, 0.33333333],\n",
       "         ...,\n",
       "         [0.01568627, 0.01568627, 0.03921569],\n",
       "         [0.01568627, 0.01568627, 0.03921569],\n",
       "         [0.01568627, 0.01568627, 0.03921569]]],\n",
       "\n",
       "\n",
       "       [[[0.16862745, 0.07058824, 0.01568627],\n",
       "         [0.16862745, 0.05882353, 0.01568627],\n",
       "         [0.14509804, 0.0627451 , 0.01176471],\n",
       "         ...,\n",
       "         [0.14117647, 0.08235294, 0.01568627],\n",
       "         [0.11372549, 0.0745098 , 0.01568627],\n",
       "         [0.05098039, 0.01176471, 0.        ]],\n",
       "\n",
       "        [[0.09019608, 0.05490196, 0.00392157],\n",
       "         [0.12941176, 0.05882353, 0.00784314],\n",
       "         [0.12156863, 0.07058824, 0.01960784],\n",
       "         ...,\n",
       "         [0.11764706, 0.04705882, 0.00784314],\n",
       "         [0.09803922, 0.04313725, 0.00392157],\n",
       "         [0.05098039, 0.01960784, 0.00784314]],\n",
       "\n",
       "        [[0.12941176, 0.04705882, 0.01176471],\n",
       "         [0.1254902 , 0.03921569, 0.01176471],\n",
       "         [0.1254902 , 0.0627451 , 0.00784314],\n",
       "         ...,\n",
       "         [0.12941176, 0.07058824, 0.01960784],\n",
       "         [0.10980392, 0.05882353, 0.01568627],\n",
       "         [0.07843137, 0.02745098, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.10980392, 0.04705882, 0.00392157],\n",
       "         [0.15294118, 0.0627451 , 0.        ],\n",
       "         [0.11372549, 0.07058824, 0.        ],\n",
       "         ...,\n",
       "         [0.13333333, 0.0627451 , 0.01176471],\n",
       "         [0.10196078, 0.0627451 , 0.01176471],\n",
       "         [0.09803922, 0.05882353, 0.01176471]],\n",
       "\n",
       "        [[0.1254902 , 0.04705882, 0.00392157],\n",
       "         [0.11372549, 0.05490196, 0.00392157],\n",
       "         [0.10980392, 0.04705882, 0.00392157],\n",
       "         ...,\n",
       "         [0.15294118, 0.06666667, 0.01568627],\n",
       "         [0.14117647, 0.05490196, 0.00784314],\n",
       "         [0.15686275, 0.0627451 , 0.01568627]],\n",
       "\n",
       "        [[0.15294118, 0.08627451, 0.03529412],\n",
       "         [0.15686275, 0.04705882, 0.00784314],\n",
       "         [0.12156863, 0.0745098 , 0.01960784],\n",
       "         ...,\n",
       "         [0.15686275, 0.05882353, 0.01176471],\n",
       "         [0.12941176, 0.08235294, 0.03529412],\n",
       "         [0.1372549 , 0.0745098 , 0.01176471]]],\n",
       "\n",
       "\n",
       "       [[[0.34117647, 0.4745098 , 0.69411765],\n",
       "         [0.14509804, 0.13333333, 0.16470588],\n",
       "         [0.51764706, 0.44705882, 0.41960784],\n",
       "         ...,\n",
       "         [0.76078431, 0.81568627, 0.71764706],\n",
       "         [0.97647059, 0.96862745, 0.91372549],\n",
       "         [0.92156863, 0.87843137, 0.88627451]],\n",
       "\n",
       "        [[0.36862745, 0.5372549 , 0.75294118],\n",
       "         [0.19215686, 0.16862745, 0.21568627],\n",
       "         [0.4627451 , 0.4627451 , 0.51372549],\n",
       "         ...,\n",
       "         [0.42352941, 0.41960784, 0.35686275],\n",
       "         [0.61960784, 0.56862745, 0.51372549],\n",
       "         [0.83529412, 0.69411765, 0.64705882]],\n",
       "\n",
       "        [[0.32941176, 0.51764706, 0.71764706],\n",
       "         [0.19215686, 0.16470588, 0.20784314],\n",
       "         [0.50980392, 0.43921569, 0.43137255],\n",
       "         ...,\n",
       "         [0.59607843, 0.72941176, 0.65490196],\n",
       "         [0.95686275, 0.93333333, 0.89019608],\n",
       "         [0.80392157, 0.81176471, 0.75294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.10980392, 0.09803922, 0.09019608],\n",
       "         [0.10588235, 0.09411765, 0.12156863],\n",
       "         [0.21176471, 0.19215686, 0.19215686],\n",
       "         ...,\n",
       "         [0.11764706, 0.24313725, 0.41176471],\n",
       "         [0.1254902 , 0.34117647, 0.61176471],\n",
       "         [0.05490196, 0.41568627, 0.81568627]],\n",
       "\n",
       "        [[0.19607843, 0.13333333, 0.17254902],\n",
       "         [0.04313725, 0.09803922, 0.11372549],\n",
       "         [0.18431373, 0.19215686, 0.22745098],\n",
       "         ...,\n",
       "         [0.20784314, 0.29019608, 0.43921569],\n",
       "         [0.09803922, 0.21960784, 0.41960784],\n",
       "         [0.02352941, 0.37647059, 0.75294118]],\n",
       "\n",
       "        [[0.25490196, 0.23137255, 0.2745098 ],\n",
       "         [0.19215686, 0.16862745, 0.22352941],\n",
       "         [0.17254902, 0.3372549 , 0.44313725],\n",
       "         ...,\n",
       "         [0.12156863, 0.24705882, 0.40784314],\n",
       "         [0.10196078, 0.42745098, 0.81176471],\n",
       "         [0.05490196, 0.3372549 , 0.7372549 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.64313725, 0.59607843, 0.58823529],\n",
       "         [0.64313725, 0.59607843, 0.58823529],\n",
       "         [0.64313725, 0.59607843, 0.58823529],\n",
       "         ...,\n",
       "         [0.6745098 , 0.71764706, 0.83529412],\n",
       "         [0.67843137, 0.72156863, 0.83921569],\n",
       "         [0.69019608, 0.73333333, 0.85098039]],\n",
       "\n",
       "        [[0.63921569, 0.59215686, 0.58431373],\n",
       "         [0.63921569, 0.59215686, 0.58431373],\n",
       "         [0.63921569, 0.59215686, 0.58431373],\n",
       "         ...,\n",
       "         [0.67058824, 0.71372549, 0.83137255],\n",
       "         [0.6745098 , 0.71764706, 0.83529412],\n",
       "         [0.68235294, 0.7254902 , 0.84313725]],\n",
       "\n",
       "        [[0.63529412, 0.58823529, 0.58039216],\n",
       "         [0.63529412, 0.58823529, 0.58039216],\n",
       "         [0.63529412, 0.58823529, 0.58039216],\n",
       "         ...,\n",
       "         [0.66666667, 0.70980392, 0.82745098],\n",
       "         [0.6745098 , 0.71764706, 0.83529412],\n",
       "         [0.67843137, 0.72156863, 0.83921569]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2627451 , 0.37254902, 0.37647059],\n",
       "         [0.25882353, 0.36862745, 0.37254902],\n",
       "         [0.26666667, 0.37647059, 0.38431373],\n",
       "         ...,\n",
       "         [0.08235294, 0.11372549, 0.11372549],\n",
       "         [0.10196078, 0.13333333, 0.13333333],\n",
       "         [0.10980392, 0.14117647, 0.14117647]],\n",
       "\n",
       "        [[0.25490196, 0.36470588, 0.36862745],\n",
       "         [0.23529412, 0.34509804, 0.34901961],\n",
       "         [0.25882353, 0.36862745, 0.37254902],\n",
       "         ...,\n",
       "         [0.09019608, 0.12156863, 0.12156863],\n",
       "         [0.10196078, 0.13333333, 0.13333333],\n",
       "         [0.10588235, 0.1372549 , 0.1372549 ]],\n",
       "\n",
       "        [[0.25098039, 0.36470588, 0.36862745],\n",
       "         [0.21568627, 0.32941176, 0.33333333],\n",
       "         [0.23921569, 0.35294118, 0.35686275],\n",
       "         ...,\n",
       "         [0.10588235, 0.1254902 , 0.12941176],\n",
       "         [0.10196078, 0.12941176, 0.12941176],\n",
       "         [0.10588235, 0.1254902 , 0.12941176]]],\n",
       "\n",
       "\n",
       "       [[[0.00784314, 0.00392157, 0.01176471],\n",
       "         [0.00784314, 0.00392157, 0.01176471],\n",
       "         [0.00784314, 0.00392157, 0.01176471],\n",
       "         ...,\n",
       "         [0.00392157, 0.        , 0.00784314],\n",
       "         [0.00392157, 0.        , 0.00784314],\n",
       "         [0.00392157, 0.        , 0.00784314]],\n",
       "\n",
       "        [[0.00784314, 0.00392157, 0.01176471],\n",
       "         [0.00784314, 0.00392157, 0.01176471],\n",
       "         [0.00784314, 0.00392157, 0.01176471],\n",
       "         ...,\n",
       "         [0.00392157, 0.        , 0.00784314],\n",
       "         [0.00392157, 0.        , 0.00784314],\n",
       "         [0.00392157, 0.        , 0.00784314]],\n",
       "\n",
       "        [[0.00784314, 0.00392157, 0.01176471],\n",
       "         [0.00784314, 0.00392157, 0.01176471],\n",
       "         [0.00784314, 0.00392157, 0.01176471],\n",
       "         ...,\n",
       "         [0.00392157, 0.        , 0.00784314],\n",
       "         [0.00392157, 0.        , 0.00784314],\n",
       "         [0.00392157, 0.        , 0.00784314]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.00392157, 0.04313725],\n",
       "         [0.00784314, 0.00392157, 0.03921569],\n",
       "         [0.00392157, 0.00784314, 0.03137255],\n",
       "         ...,\n",
       "         [0.        , 0.03137255, 0.17647059],\n",
       "         [0.        , 0.02352941, 0.14117647],\n",
       "         [0.00392157, 0.02352941, 0.13333333]],\n",
       "\n",
       "        [[0.00392157, 0.        , 0.03921569],\n",
       "         [0.00392157, 0.        , 0.03529412],\n",
       "         [0.00392157, 0.00392157, 0.02745098],\n",
       "         ...,\n",
       "         [0.        , 0.02745098, 0.16470588],\n",
       "         [0.        , 0.01568627, 0.1254902 ],\n",
       "         [0.        , 0.01568627, 0.10980392]],\n",
       "\n",
       "        [[0.        , 0.        , 0.03529412],\n",
       "         [0.        , 0.        , 0.03137255],\n",
       "         [0.        , 0.        , 0.02352941],\n",
       "         ...,\n",
       "         [0.        , 0.02352941, 0.14901961],\n",
       "         [0.        , 0.00392157, 0.10196078],\n",
       "         [0.        , 0.00784314, 0.09803922]]],\n",
       "\n",
       "\n",
       "       [[[0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         ...,\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255]],\n",
       "\n",
       "        [[0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         ...,\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255]],\n",
       "\n",
       "        [[0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         ...,\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         ...,\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255]],\n",
       "\n",
       "        [[0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         ...,\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255]],\n",
       "\n",
       "        [[0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         ...,\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255],\n",
       "         [0.01176471, 0.02745098, 0.03137255]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, concatenate, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(150,150,3))\n",
    "x = Conv2D(64, (3,3), activation='relu')(input_img)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "image_model = Model(inputs=input_img, outputs=x)\n",
    "\n",
    "input_int = Input(shape=(1,))\n",
    "y = Dense(128, activation='relu')(input_int)\n",
    "gal_model = Model(inputs=input_int, outputs=y)\n",
    "\n",
    "merged = concatenate([image_model.output, gal_model.output])\n",
    "merged = Dense(128, activation='relu')(merged)\n",
    "merged = Dense(2, activation='softmax')(merged)\n",
    "\n",
    "model = Model(inputs=[image_model.input, gal_model.input], outputs=merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 80s 2s/step - loss: 247.4182 - accuracy: 0.5731 - val_loss: 0.8780 - val_accuracy: 0.5933\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.6997 - accuracy: 0.6821 - val_loss: 0.5564 - val_accuracy: 0.7768\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 47s 2s/step - loss: 0.3862 - accuracy: 0.8200 - val_loss: 0.2133 - val_accuracy: 0.9270\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 40s 1s/step - loss: 0.3196 - accuracy: 0.8759 - val_loss: 0.1602 - val_accuracy: 0.9442\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 41s 1s/step - loss: 0.1298 - accuracy: 0.9551 - val_loss: 0.0834 - val_accuracy: 0.9721\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 42s 1s/step - loss: 0.0712 - accuracy: 0.9761 - val_loss: 0.0565 - val_accuracy: 0.9807\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 42s 1s/step - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.0636 - val_accuracy: 0.9785\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 42s 1s/step - loss: 0.0430 - accuracy: 0.9872 - val_loss: 0.2079 - val_accuracy: 0.9303\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 43s 1s/step - loss: 0.1139 - accuracy: 0.9542 - val_loss: 0.0258 - val_accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 43s 1s/step - loss: 0.0287 - accuracy: 0.9931 - val_loss: 0.0213 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x267d2c950a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "arc_lengths = np.array(arc_lengths)\n",
    "model.fit([X,arc_lengths],y, epochs=10, validation_data=([X,arc_lengths],y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 64x2-CNN_impure_gal.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('64x2-CNN_impure_gal.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
